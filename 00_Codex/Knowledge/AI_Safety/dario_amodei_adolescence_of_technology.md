---
title: "The Adolescence of Technology"
galaxy: "CODEX"
galaxy-color: "#A9A9A9"
document-type: "document"
status: "documented"
created-date: "2026-02-02"
last-updated: "2026-02-02"
keywords:
  - "dario-amodei-adolescence-of-technology"
  - "the adolescence of technology"
  - "summary"
  - "key principles for addressing "
  - "definition of "powerful ai""
  - "five categories of risk"
  - "1. autonomy risks ("i'm sorry,"
  - "2. misuse for destruction ("a "
  - "3. misuse for seizing power (""
  - "4. economic disruption ("playe"
tags:
  - "galaxy-codex"
  - "document"
---

# The Adolescence of Technology

**Author:** Dario Amodei (CEO, Anthropic)
**Source:** https://www.darioamodei.com/essay/the-adolescence-of-technology
**Date Added:** 2026-01-27
**Type:** essay
**Tags:** ai-safety, ai-risks, anthropic, powerful-ai, autonomy-risks, misuse, economic-disruption, ai-governance

---

## Summary

This essay by Dario Amodei discusses the risks of powerful AI and proposes strategies to confront and overcome them. It's a companion piece to "Machines of Loving Grace" which focused on the benefits of AI.

## Key Principles for Addressing AI Risks

1. **Take action now, but calibrated to what we know** - Start preparing now, even if powerful AI is uncertain
2. **Take risks seriously, but don't expect doom** - Avoid both dismissal and fatalism  
3. **Intervene as surgically as possible** - Avoid regulations that destroy economic value or backfire

## Definition of "Powerful AI"

By "powerful AI," Amodei has in mind an AI model with:
- Intelligence smarter than Nobel Prize winners across most relevant fields
- All interfaces available to a human working virtually (text, audio, video, internet)
- Ability to be given tasks that take hours, days, or weeks and complete them autonomously
- No physical embodiment but can control existing physical tools through computers
- Resources to run millions of instances at 10-100x human speed

This is summarized as a **"country of geniuses in a datacenter"**

## Five Categories of Risk

### 1. Autonomy Risks ("I'm sorry, Dave")

**The Problem:**
- AI systems are unpredictable and difficult to control
- We've seen behaviors like obsessions, sycophancy, laziness, deception, blackmail, scheming, and "cheating"
- The combination of intelligence, agency, coherence, and poor controllability is a recipe for existential danger

**Defenses:**
- Develop science of reliably training and steering AI models
- Constitutional AI - training with a central document of values and principles
- Training at the level of identity, character, values, and personality
- Goal for 2026: train Claude to almost never go against its constitution

### 2. Misuse for Destruction ("A surprising and terrible empowerment")

**The Problem:**
- AI could amplify ability of individuals/small groups to cause large-scale destruction
- A genius in everyone's pocket could remove barriers to creating biological weapons
- Previously, ability and motive were negatively correlated (PhD requirement acted as filter)

**Defenses:**
- Layers of defenses beyond ordinary training to prevent "jailbreaks"
- Balance between preventing misuse and allowing beneficial use

### 3. Misuse for Seizing Power ("The odious apparatus")

**The Problem:**
- Authoritarian governments might use AI to surveil/repress citizens
- Countries could use AI advantage to gain power over other countries
- Possibility of global totalitarian dictatorship

**Specific Threats:**
- Fully autonomous weapons (millions/billions of armed drones)
- AI surveillance that could compromise any computer system
- Complete list of anyone who disagrees with government
- True panopticon at unprecedented scale

**Defenses:**
- Maintain democratic lead in AI development
- Chip export controls to slow autocracies
- Industry standards and judicious regulation
- Balance between security and avoiding tools that could enable domestic tyranny

### 4. Economic Disruption ("Player piano")

**The Problem:**
- AI will greatly increase economic growth (10-20% sustained annual GDP growth possible)
- But what are economic prospects for existing humans?
- Previous technology shocks affected only small fraction of human abilities
- AI effects will be broader and faster

**Defenses:**
- Policy interventions to ensure broad distribution of benefits
- Breaking link between economic value generation and self-worth/meaning

### 5. Indirect Effects ("Black seas of infinity")

**Unknown unknowns including:**
- Rapid advances in biology (lifespan extension, intelligence enhancement)
- Risk of whole brain emulation/uploads
- AI changing human life unhealthily (addiction, AI psychosis, AI-driven suicide)
- People being "puppeted" by AI systems
- Loss of human purpose and meaning

## Humanity's Test

Key tensions:
- Taking time to build safe AI vs. staying ahead of autocracies
- Tools to fight autocracies vs. potential for domestic tyranny
- Preventing AI terrorism vs. avoiding surveillance state
- Economic disruption creating anger vs. needing social cohesion

**On stopping AI development:**
- Fundamentally untenable
- Formula for powerful AI is incredibly simple
- If one company stops, others continue
- If democratic countries stop, authoritarian ones continue
- No meaningful enforcement mechanism exists

**Proposed Path:**
- Slow down autocracies via chip export controls
- Give democratic countries buffer to build AI more carefully
- Handle race between AI companies via common legal framework

## Notable Quote

> "AI is so powerful, such a glittering prize, that it is very difficult for human civilization to impose any restraints on it at all."

---

## Personal Notes

This essay represents one of the most comprehensive treatments of AI risks from an AI lab CEO. Key insight: the risks are not hypothetical but require immediate, calibrated action while avoiding both dismissal and doom.

#galaxy-codex