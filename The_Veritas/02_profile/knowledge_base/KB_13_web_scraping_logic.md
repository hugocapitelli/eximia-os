# KB_13 ‚Äî Web Scraping Logic & Robots.txt

## Categoria: INVARIANTES
## Palavras: ~1,500
## Atualizado: 2026-01-07

---

## 1. O que √© Robots.txt

### Defini√ß√£o

Arquivo que informa crawlers quais partes do site podem ou n√£o ser acessadas.

**Localiza√ß√£o:** `https://example.com/robots.txt`

### Sintaxe B√°sica

```
User-agent: *        # Aplica a todos os crawlers
Disallow: /admin/    # N√£o acessar /admin/
Allow: /public/      # Permitir /public/
Crawl-delay: 10      # Esperar 10s entre requests
```

---

## 2. A√ß√µes para The_Veritas

### ‚úÖ Permitido

| A√ß√£o | Justificativa |
| :--- | :--- |
| Ler dados p√∫blicos | Informa√ß√£o dispon√≠vel para todos |
| Citar com atribui√ß√£o | Fair use para pesquisa |
| Acessar APIs p√∫blicas | Uso autorizado |
| Usar cached versions | Google Cache, Wayback |

### ‚ùå Proibido

| A√ß√£o | Justificativa |
| :--- | :--- |
| Ignorar robots.txt | Viola√ß√£o de ToS |
| Bypass paywall | Ilegal na maioria dos casos |
| Scrape dados pessoais | Viola√ß√£o LGPD/GDPR |
| DDoS / requests excessivos | Dano ao site |
| Bypass autentica√ß√£o | Acesso n√£o autorizado |

---

## 3. Alternativas √âticas

| Se precisar de | Fa√ßa |
| :--- | :--- |
| Artigo atr√°s de paywall | Busque vers√£o em reposit√≥rios acad√™micos (arXiv, SSRN) |
| Dados hist√≥ricos | Use Wayback Machine (archive.org) |
| Dados agregados | Busque relat√≥rios p√∫blicos |
| Dados privados | Solicite via canais oficiais |

---

## 4. Refer√™ncias

- Internet Archive. *Wayback Machine*.
- Google. *Robots.txt Specifications*.


---


<!-- ORACLE:OBSIDIAN_CONNECTIONS_START -->


## üß† Obsidian Connections


**Family:** [[Agentes]]


<!-- ORACLE:OBSIDIAN_CONNECTIONS_END -->