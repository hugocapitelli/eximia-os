# KB_04 â€” ViÃ©s Cognitivo e FalÃ¡cias LÃ³gicas

## Categoria: TEORIA
## Palavras: ~3,000
## Atualizado: 2026-01-07

---

## 1. Por Que Estudar ViÃ©s?

> *"Os analistas nÃ£o veem o mundo como ele Ã©. Veem o mundo como esperam que seja."*
> â€” Richards J. Heuer Jr., Psychology of Intelligence Analysis (1999)

### O Problema Fundamental

Nosso cÃ©rebro usa atalhos (heurÃ­sticas) para processar informaÃ§Ã£o rapidamente. Esses atalhos funcionam 95% do tempo, mas **causam erros sistemÃ¡ticos em anÃ¡lise**.

---

## 2. Vieses Cognitivos Principais

### A. ViÃ©s de ConfirmaÃ§Ã£o

> *"A tendÃªncia de buscar, interpretar e lembrar informaÃ§Ã£o que confirma nossas crenÃ§as."*
> â€” Raymond Nickerson (1998)

**Como afeta pesquisa:**
- Buscamos fontes que concordam conosco
- Ignoramos evidÃªncia contrÃ¡ria
- Interpretamos dados ambÃ­guos a nosso favor

**MitigaÃ§Ã£o:**
- Buscar ativamente evidÃªncia contrÃ¡ria
- Usar ACH (Analysis of Competing Hypotheses)
- Perguntar: *"O que provaria que estou errado?"*

### B. ViÃ©s de Ancoragem

> *"A primeira informaÃ§Ã£o que recebemos ancora todas as estimativas subsequentes."*
> â€” Kahneman & Tversky (1974)

**Exemplo:**
- Primeiro relatÃ³rio diz mercado = R$ 10B
- Todos os relatÃ³rios subsequentes sÃ£o "comparados" a R$ 10B
- Mesmo se metodologia do primeiro for fraca

**MitigaÃ§Ã£o:**
- NÃ£o comeÃ§ar pela estimativa mais acessÃ­vel
- Buscar mÃºltiplas estimativas independentes
- Fazer "base rates" antes de ver dados

### C. ViÃ©s de Disponibilidade

> *"Superestimamos a probabilidade de eventos que lembramos facilmente."*
> â€” Kahneman & Tversky (1973)

**Exemplo:**
- Startups de AI dominam notÃ­cias
- ConcluÃ­mos que "todas as startups sÃ£o de AI"
- Ignoramos setores menos midiÃ¡ticos

**MitigaÃ§Ã£o:**
- Buscar dados agregados, nÃ£o casos
- Desconfiar de narrativas "quentes"
- Perguntar: *"Isso Ã© estatisticamente comum ou apenas memorÃ¡vel?"*

### D. ViÃ©s de SobrevivÃªncia

> *"Focamos nos vencedores e ignoramos os que falharam."*
> â€” Abraham Wald (1943)

**Exemplo:**
- "Todas as unicÃ³rnios fizeram X" â†’ ignoramos 99% que fizeram X e falharam
- Benchmarks de SaaS sÃ£o de empresas que sobreviveram

**MitigaÃ§Ã£o:**
- Buscar dados de empresas que falharam
- Perguntar: *"E os que nÃ£o conseguiram?"*
- Calcular taxa base de sucesso

### E. ViÃ©s de RecÃªncia

> *"Damos mais peso a informaÃ§Ã£o recente do que a histÃ³rica."*
> â€” Ebbinghaus (1885)

**Exemplo:**
- "O dÃ³lar subiu 20% este mÃªs, vai continuar subindo"
- Ignoramos ciclos histÃ³ricos

**MitigaÃ§Ã£o:**
- Analisar sÃ©ries histÃ³ricas longas
- Comparar com mÃºltiplos ciclos
- Desconfiar de extrapolaÃ§Ãµes lineares

---

## 3. FalÃ¡cias LÃ³gicas Comuns

### A. CorrelaÃ§Ã£o vs Causalidade

> *"CorrelaÃ§Ã£o nÃ£o implica causalidade."*

**Exemplo falacioso:**
- "PaÃ­ses que comem mais chocolate tÃªm mais Nobel"
- ConclusÃ£o errada: Chocolate causa inteligÃªncia
- Realidade: Ambos correlacionam com riqueza

**DetecÃ§Ã£o:**
- Buscar mecanismo causal plausÃ­vel
- Verificar se hÃ¡ variÃ¡vel confundidora
- Perguntar: *"O que mais poderia explicar isso?"*

### B. Post Hoc Ergo Propter Hoc

> *"Depois disso, portanto por causa disso."*

**Exemplo:**
- "Implementamos CRM â†’ vendas subiram"
- Na verdade: Mercado estava aquecido

**DetecÃ§Ã£o:**
- Buscar grupo de controle
- Verificar timing vs causalidade
- Considerar explicaÃ§Ãµes alternativas

### C. Apelo Ã  Autoridade

> *"Se X disse, deve ser verdade."*

**Exemplo:**
- "Elon Musk disse que AI vai substituir todos"
- Musk Ã© expert em foguetes, nÃ£o necessariamente em AI

**DetecÃ§Ã£o:**
- Verificar se autoridade Ã© relevante ao tema
- Buscar consenso de mÃºltiplos experts
- Avaliar se hÃ¡ conflito de interesse

### D. Cherry Picking

> *"Selecionar apenas dados que suportam a conclusÃ£o."*

**Exemplo:**
- Mostrar crescimento de Q4 (melhor) e omitir Q1-Q3 (ruins)
- RelatÃ³rio de startup destacando Ãºnica mÃ©trica positiva

**DetecÃ§Ã£o:**
- Pedir dados completos
- Verificar sÃ©rie temporal inteira
- Buscar mÃ©tricas que foram omitidas

### E. FalÃ¡cia do Espantalho

> *"Distorcer argumento do oponente para refutÃ¡-lo facilmente."*

**Exemplo:**
- "CrÃ­ticos dizem que SaaS Ã© ruim" (distorÃ§Ã£o)
- CrÃ­ticos reais dizem: "SaaS em segmento X tem CAC alto"

**DetecÃ§Ã£o:**
- Buscar fonte original da crÃ­tica
- Verificar se representaÃ§Ã£o Ã© fiel
- Ler ambos os lados diretamente

---

## 4. HeurÃ­sticas (Atalhos Mentais)

### HeurÃ­stica de Representatividade
- Julgamos probabilidade por semelhanÃ§a ao estereÃ³tipo
- "Parece uma startup de sucesso" â†’ assumimos que terÃ¡ sucesso

### HeurÃ­stica de Afeto
- DecisÃµes baseadas em emoÃ§Ã£o, nÃ£o anÃ¡lise
- "Gosto do founder" â†’ ignoro red flags financeiros

### HeurÃ­stica de EsforÃ§o
- Se algo exigiu esforÃ§o, valorizamos mais
- RelatÃ³rio longo = relatÃ³rio bom (nÃ£o necessariamente)

---

## 5. Matriz de MitigaÃ§Ã£o

| ViÃ©s | TÃ©cnica de MitigaÃ§Ã£o |
| :--- | :--- |
| ConfirmaÃ§Ã£o | ACH, buscar evidÃªncia contrÃ¡ria |
| Ancoragem | Estimativas independentes primeiro |
| Disponibilidade | Dados agregados vs casos |
| SobrevivÃªncia | Incluir fracassos na anÃ¡lise |
| RecÃªncia | SÃ©ries histÃ³ricas longas |
| CorrelaÃ§Ã£o/Causalidade | Buscar mecanismo, variÃ¡veis |
| Cherry Picking | Solicitar dados completos |

---

## 6. Devil's Advocacy Protocol

### Objetivo
ForÃ§ar consideraÃ§Ã£o de hipÃ³teses alternativas.

### Processo

```
1. HIPÃ“TESE PRINCIPAL
   "O mercado de AgTech vai crescer 25% em 2025"
   
2. DEVIL'S ADVOCATE
   "Por que o mercado NÃƒO cresceria 25%?"
   
3. CONTRA-ARGUMENTOS
   - RecessÃ£o agrÃ­cola
   - Queda de commodities
   - RegulaÃ§Ã£o desfavorÃ¡vel
   - ConsolidaÃ§Ã£o reduz novos entrantes
   
4. AVALIAÃ‡ÃƒO
   Probabilidade de cenÃ¡rio negativo: 30%
   Ajuste: Crescimento esperado 15-25% (range)
```

---

## 7. Inversion (Munger)

> *"Inverta, sempre inverta."*
> â€” Charlie Munger

### AplicaÃ§Ã£o

| Pergunta Normal | Pergunta Invertida |
| :--- | :--- |
| Como ter sucesso em SaaS? | Como garantir fracasso em SaaS? |
| Por que investir em X? | Por que NÃƒO investir em X? |
| Quais os benefÃ­cios? | Quais os riscos ocultos? |

---

## 8. ReferÃªncias

- Kahneman, D. (2011). *Thinking, Fast and Slow*. Farrar, Straus and Giroux.
- Heuer, R. J. (1999). *Psychology of Intelligence Analysis*. CIA.
- Nickerson, R. S. (1998). *Confirmation Bias*. Review of General Psychology.
- Munger, C. (1995). *The Psychology of Human Misjudgment*. Lecture.
- Dobelli, R. (2013). *The Art of Thinking Clearly*.


---


<!-- ORACLE:OBSIDIAN_CONNECTIONS_START -->


## ðŸ§  Obsidian Connections


**Family:** [[Agentes]]


<!-- ORACLE:OBSIDIAN_CONNECTIONS_END -->